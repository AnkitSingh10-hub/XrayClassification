{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHnsGR3LXSNPmJtHY4DB3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkitSingh10-hub/XrayClassification/blob/main/pneumonia_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DC_xdB7v56a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343bc2f1-df03-42ac-98b6-699a55cdb682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.4/256.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataset...\n",
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [01:45<00:00, 25.0MB/s]\n",
            "100% 2.29G/2.29G [01:45<00:00, 23.3MB/s]\n",
            "Unzipping data... (this might take a minute)\n",
            "DONE! Data is ready in folder: /content/chest_xray\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 1. Set the API Token directly (From your screenshot)\n",
        "# This authenticates you without needing to upload the kaggle.json file\n",
        "os.environ['KAGGLE_API_TOKEN'] = 'KGAT_b5bae63bd58fdd2f74964cade51c4ad7'\n",
        "os.environ['KAGGLE_USERNAME'] = \"ankitsingh388\" # I see your username in the background\n",
        "\n",
        "# 2. Update the Kaggle library to ensure it supports this token type\n",
        "!pip install -q -U kaggle\n",
        "\n",
        "# 3. Download the Chest X-Ray Dataset\n",
        "print(\"Downloading dataset...\")\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "# 4. Unzip the data\n",
        "print(\"Unzipping data... (this might take a minute)\")\n",
        "!unzip -q chest-xray-pneumonia.zip\n",
        "\n",
        "print(\"DONE! Data is ready in folder: /content/chest_xray\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE THIS PATH IN YOUR CODE\n",
        "# In VS Code it was likely just 'chest_xray', but in Colab it is here:\n",
        "data_dir = '/content/chest_xray/chest_xray'\n",
        "\n",
        "# Example of how your loader setup should look now:\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# Verify it works\n",
        "print(os.listdir(train_dir))\n",
        "# Should print ['NORMAL', 'PNEUMONIA']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQPGZAX0VeD",
        "outputId": "1c8218b1-a3af-4750-8fee-b4995d5e2e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.DS_Store', 'NORMAL', 'PNEUMONIA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PROJECT: Deep Learning for Medical Imaging (Pneumonia Detection)\n",
        "# RESUME MATCH: PyTorch, ResNet-18, Weighted Loss, Geometric Augmentation\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Imports and Setup\n",
        "# --------------------------------------------\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Metrics\n",
        "try:\n",
        "    from torchmetrics import Accuracy, F1Score, Recall\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    import sys\n",
        "    print(\"Installing torchmetrics...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchmetrics\"])\n",
        "    from torchmetrics import Accuracy, F1Score, Recall\n",
        "\n",
        "# Device configuration (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 101010\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# 2. Data Preparation\n",
        "# --------------------------------------------\n",
        "\n",
        "# ===> FIX: CHANGED PATH FOR COLAB <===\n",
        "data_dir = '/content/chest_xray/chest_xray'\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "val_dir = os.path.join(data_dir, 'val')\n",
        "\n",
        "# Check if folders exist\n",
        "print(f\"Checking path: {train_dir}\")\n",
        "if not os.path.exists(train_dir):\n",
        "    print(f\"ERROR: Train folder still not found. Please run the Kaggle download cell first.\")\n",
        "else:\n",
        "    print(\"Train folder found!\")\n",
        "\n",
        "# RESUME MATCH: \"Dynamic data augmentation (geometric transformations)\"\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load Datasets\n",
        "try:\n",
        "    print(f\"Loading data from: {data_dir}\")\n",
        "    train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
        "    test_dataset = ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "    # ===> NOTE: Changed num_workers to 2 for faster processing in Colab <===\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    print(\"Data loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    train_dataset = []\n",
        "    test_dataset = []\n",
        "\n",
        "# 3. Model Architecture\n",
        "# --------------------------------------------\n",
        "# RESUME MATCH: \"Transfer Learning (ResNet-18)\"\n",
        "\n",
        "# Load pre-trained model\n",
        "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# Freeze parameters (Feature Extraction)\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify final layer for Binary Classification\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 1)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "# 4. Methodology: Weighted Loss Strategy\n",
        "# --------------------------------------------\n",
        "# RESUME MATCH: \"Weighted Cross-Entropy Loss to penalize false negatives\"\n",
        "\n",
        "def get_pos_weight(dataset):\n",
        "    if len(dataset) == 0: return torch.tensor([1.0]).to(device)\n",
        "\n",
        "    # Calculate class distribution\n",
        "    targets = torch.tensor(dataset.targets)\n",
        "    class_0_count = (targets == 0).sum() # Normal\n",
        "    class_1_count = (targets == 1).sum() # Pneumonia\n",
        "\n",
        "    print(f\"Class Distribution -> Normal: {class_0_count}, Pneumonia: {class_1_count}\")\n",
        "\n",
        "    if class_1_count == 0: return torch.tensor([1.0]).to(device)\n",
        "\n",
        "    # Weight = Number of Negatives / Number of Positives\n",
        "    weight = class_0_count / class_1_count\n",
        "    return torch.tensor([weight], dtype=torch.float32).to(device)\n",
        "\n",
        "if len(train_dataset) > 0:\n",
        "    pos_weight = get_pos_weight(train_dataset)\n",
        "else:\n",
        "    pos_weight = torch.tensor([1.0]).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.001)\n",
        "\n",
        "# 5. Training Loop\n",
        "# --------------------------------------------\n",
        "\n",
        "def train_model(model, loader, criterion, optimizer, epochs=5):\n",
        "    print(\"\\nStarting Training...\")\n",
        "    print(f\"Training for {epochs} epochs on {device}...\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(loader):\n",
        "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "            labels = labels.unsqueeze(1) # Match shape [Batch, 1]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            if i % 20 == 0:\n",
        "                print(f\"  Epoch {epoch+1}, Batch {i}/{len(loader)}\")\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# Train the model\n",
        "if len(train_dataset) > 0:\n",
        "    train_model(resnet18, train_loader, criterion, optimizer, epochs=5)\n",
        "\n",
        "# 6. Evaluation\n",
        "# --------------------------------------------\n",
        "# RESUME MATCH: \"Result: Achieved a measurable improvement in Recall (Sensitivity)\"\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize Metrics\n",
        "    accuracy_metric = Accuracy(task=\"binary\").to(device)\n",
        "    f1_metric = F1Score(task=\"binary\").to(device)\n",
        "    recall_metric = Recall(task=\"binary\").to(device) # Sensitivity\n",
        "\n",
        "    print(\"\\nEvaluating on Test Set...\")\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.sigmoid(outputs).round()\n",
        "\n",
        "            accuracy_metric.update(preds, labels.unsqueeze(1))\n",
        "            f1_metric.update(preds, labels.unsqueeze(1))\n",
        "            recall_metric.update(preds, labels.unsqueeze(1))\n",
        "\n",
        "    final_acc = accuracy_metric.compute().item()\n",
        "    final_f1 = f1_metric.compute().item()\n",
        "    final_recall = recall_metric.compute().item()\n",
        "\n",
        "    print(\"\\n=== Final Evaluation ===\")\n",
        "    print(f\"Accuracy: {final_acc:.4f}\")\n",
        "    print(f\"F1 Score: {final_f1:.4f}\")\n",
        "    print(f\"Recall (Sensitivity): {final_recall:.4f} <--- Key Resume Metric\")\n",
        "\n",
        "if len(test_dataset) > 0:\n",
        "    evaluate_model(resnet18, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5ky5f-10Xe_",
        "outputId": "10f6e33a-3de2-4cb9-a81d-795312f2bdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Checking path: /content/chest_xray/chest_xray/train\n",
            "Train folder found!\n",
            "Loading data from: /content/chest_xray/chest_xray\n",
            "Data loaded successfully.\n",
            "Class Distribution -> Normal: 1341, Pneumonia: 3875\n",
            "\n",
            "Starting Training...\n",
            "Training for 5 epochs on cuda...\n",
            "  Epoch 1, Batch 0/163\n",
            "  Epoch 1, Batch 20/163\n",
            "  Epoch 1, Batch 40/163\n",
            "  Epoch 1, Batch 60/163\n",
            "  Epoch 1, Batch 80/163\n",
            "  Epoch 1, Batch 100/163\n",
            "  Epoch 1, Batch 120/163\n",
            "  Epoch 1, Batch 140/163\n",
            "  Epoch 1, Batch 160/163\n",
            "Epoch [1/5] Loss: 0.2116\n",
            "  Epoch 2, Batch 0/163\n",
            "  Epoch 2, Batch 20/163\n",
            "  Epoch 2, Batch 40/163\n",
            "  Epoch 2, Batch 60/163\n",
            "  Epoch 2, Batch 80/163\n",
            "  Epoch 2, Batch 100/163\n",
            "  Epoch 2, Batch 120/163\n",
            "  Epoch 2, Batch 140/163\n",
            "  Epoch 2, Batch 160/163\n",
            "Epoch [2/5] Loss: 0.1333\n",
            "  Epoch 3, Batch 0/163\n",
            "  Epoch 3, Batch 20/163\n",
            "  Epoch 3, Batch 40/163\n",
            "  Epoch 3, Batch 60/163\n",
            "  Epoch 3, Batch 80/163\n",
            "  Epoch 3, Batch 100/163\n",
            "  Epoch 3, Batch 120/163\n",
            "  Epoch 3, Batch 140/163\n",
            "  Epoch 3, Batch 160/163\n",
            "Epoch [3/5] Loss: 0.1179\n",
            "  Epoch 4, Batch 0/163\n",
            "  Epoch 4, Batch 20/163\n",
            "  Epoch 4, Batch 40/163\n",
            "  Epoch 4, Batch 60/163\n",
            "  Epoch 4, Batch 80/163\n",
            "  Epoch 4, Batch 100/163\n",
            "  Epoch 4, Batch 120/163\n",
            "  Epoch 4, Batch 140/163\n",
            "  Epoch 4, Batch 160/163\n",
            "Epoch [4/5] Loss: 0.1084\n",
            "  Epoch 5, Batch 0/163\n",
            "  Epoch 5, Batch 20/163\n",
            "  Epoch 5, Batch 40/163\n",
            "  Epoch 5, Batch 60/163\n",
            "  Epoch 5, Batch 80/163\n",
            "  Epoch 5, Batch 100/163\n",
            "  Epoch 5, Batch 120/163\n",
            "  Epoch 5, Batch 140/163\n",
            "  Epoch 5, Batch 160/163\n",
            "Epoch [5/5] Loss: 0.1073\n",
            "\n",
            "Evaluating on Test Set...\n",
            "\n",
            "=== Final Evaluation ===\n",
            "Accuracy: 0.8830\n",
            "F1 Score: 0.9031\n",
            "Recall (Sensitivity): 0.8718 <--- Key Resume Metric\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Save the model to Colab's local disk\n",
        "torch.save(resnet18.state_dict(), 'pneumonia_resnet18.pth')\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# 2. Download it to your computer (Optional but recommended)\n",
        "from google.colab import files\n",
        "files.download('pneumonia_resnet18.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "TywQWeOC4DOA",
        "outputId": "8fa4e807-dc20-4197-e7d2-b59308392e74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e36ea1f1-51be-45e8-9284-74bfb22e6c65\", \"pneumonia_resnet18.pth\", 44788747)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}